{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ分析・操作用ライブラリ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# NLP用ライブラリ\n",
    "import MeCab,re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# スコア評価用ライブラリ\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# エラー表示の抑制\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 表示関連\n",
    "# DataFrameの列数設定\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形態素解析用関数\n",
    "def tokenize(text):\n",
    "    tokens = []\n",
    "    tagger = MeCab.Tagger()\n",
    "    node = tagger.parseToNode(text)\n",
    "    while node:\n",
    "        if node.feature.split(\",\")[0] in ['名詞'] :\n",
    "                replace_node = re.sub( re.compile( \"[!-/:-@[-`{-~]\" ), \"\", node.surface )\n",
    "                if replace_node != \"\" and replace_node != \" \":\n",
    "                    tokens.append(replace_node)\n",
    "        node = node.next\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanEmbeddingVectorizer(text, model):\n",
    "    #vectors = [keyed_vec.get_vector(token) for token in tokens if token in model.vocab]\n",
    "    mean_vectors = []\n",
    "    tagger = MeCab.Tagger()\n",
    "    node = tagger.parseToNode(text)\n",
    "    while node:\n",
    "        if node.feature.split(\",\")[0] in ['名詞'] :\n",
    "                replace_node = re.sub( re.compile( \"[!-/:-@[-`{-~]\" ), \"\", node.surface )\n",
    "                if replace_node != \"\" and replace_node != \" \":\n",
    "                    if replace_node in model.vocab:\n",
    "                        mean_vectors.append(np.mean(model.get_vector(replace_node)))\n",
    "                    else:\n",
    "                        mean_vectors.append(0.0)\n",
    "        node = node.next\n",
    "    return np.mean(mean_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ドール・フード・カンパニー  ドール・フード・カンパニー  Dole  Food  Comp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>南ヶ丘牧場  株式会社  南ヶ丘牧場  みなみ  じょう  栃木県  那須高原  本拠  酪...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>岩瀬牧場  岩瀬牧場  ぼくじょう  日本  福島県  岩瀬  郡  鏡石町  牧場  鏡石...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>くら  ぎ  GI  Co  Ltd  三重県  中心  農業  店舗  展開  会社  本...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ハッピーネモファーム  株式会社  ハッピーネモファーム  北海道  浦河  郡  浦河町 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  ドール・フード・カンパニー  ドール・フード・カンパニー  Dole  Food  Comp...       1\n",
       "1  南ヶ丘牧場  株式会社  南ヶ丘牧場  みなみ  じょう  栃木県  那須高原  本拠  酪...       1\n",
       "2  岩瀬牧場  岩瀬牧場  ぼくじょう  日本  福島県  岩瀬  郡  鏡石町  牧場  鏡石...       1\n",
       "3  くら  ぎ  GI  Co  Ltd  三重県  中心  農業  店舗  展開  会社  本...       1\n",
       "4  ハッピーネモファーム  株式会社  ハッピーネモファーム  北海道  浦河  郡  浦河町 ...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# テキストデータの読み込み\n",
    "wikiData = pd.read_csv(\"csv/train_cleaned.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# 読み込みデータの表示\n",
    "wikiData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy配列へ変換\n",
    "X = wikiData.text.values\n",
    "y = wikiData.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータ、テストデータの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X , y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDFへ変換\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize)\n",
    "vectorizer.fit(X)\n",
    "train_array = vectorizer.transform(X_train).toarray()\n",
    "test_array = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.keyedvectors as word2vec_for_txt\n",
    "model_dir = 'model/fastText.model.vec'\n",
    "model = word2vec_for_txt.KeyedVectors.load_word2vec_format(model_dir, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    X_train[i] = MeanEmbeddingVectorizer(X_train[i], model)\n",
    "    \n",
    "for i in range(len(X_test)):\n",
    "    X_test[i] = MeanEmbeddingVectorizer(X_test[i], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_pd1 = pd.concat([pd.DataFrame(train_array),pd.DataFrame(X_train)],axis=1)\n",
    "work_pd2 = pd.concat([pd.DataFrame(train_array),pd.DataFrame(X_train)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = work_pd1.values\n",
    "X_text2 = work_pd2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light GBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "clf = lgb.LGBMClassifier(objective='multiclass', num_class=33)\n",
    "clf.fit(train_array, y_train)\n",
    "cv_scores = cross_val_score(clf, train_array, y_train, cv=5)\n",
    "\n",
    "print(\"Training score：\" + str(clf.score(train_array, y_train)))\n",
    "print(\"Cross-Validation score：\" + str(np.mean(cv_scores)))\n",
    "print(\"Test score：\" + str(clf.score(test_array, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
